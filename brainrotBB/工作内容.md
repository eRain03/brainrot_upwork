Eldorado.gg 市场价格爬虫方案
这个方案是针对 Eldorado.gg 平台的 Brainrot 物品市场数据爬取设计的，目的是从搜索页抓取同款或相似物品的最低价格列表，包括价格、卖家名和评价。方案详细、可执行，适合交给工程师直接开发。焦点只在爬虫部分，不涉及其他模块（如图片处理或 UI）。工程师只需关注 Python 代码的实现、测试和部署。
1. 项目目标

输入：一个搜索查询字符串（如 "Lava Skibidi Toilet Rainbow 5 traits"），由后端接收（例如从 API 参数）。
输出：一个 JSON 列表，包含最低价的 5-10 条物品信息，例如：JSON[
  {"price": 600.0, "seller": "seller123", "reviews": "4.8 (15 reviews)", "url": "https://www.eldorado.gg/item/12345"},
  {"price": 650.0, "seller": "protrader", "reviews": "5.0 (8 reviews)", "url": "https://www.eldorado.gg/item/67890"}
]
功能：爬取 Eldorado.gg 的搜索结果页，按价格升序排序，提取关键字段。
性能要求：每次查询响应 <10 秒；每天查询上限 100 次（防 ban）。
准确性：优先抓取精确匹配的 Brainrot 物品；如果无结果，返回空列表。

2. 技术栈

语言：Python 3.10+
核心库：
requests：发送 HTTP 请求。
beautifulsoup4：解析 HTML。
fake-useragent：随机生成 User-Agent 防 ban。
tenacity：重试机制。
cachetools：缓存结果（TTL 缓存，30 分钟过期）。

可选升级：如果页面动态加载，用 playwright（浏览器自动化）。
安装命令：Bashpip install requests beautifulsoup4 fake-useragent tenacity cachetools如果用 playwright：Bashpip install playwright
playwright install

3. 实现步骤

准备查询：查询字符串基于 Brainrot 名称、mutation 和 traits 数量组合，例如 "brainrot name mutation traits count"。
发送请求：用 GET 请求访问搜索页 URL，如 "https://www.eldorado.gg/search?q=query&sort=price_asc"。
解析 HTML：
用 BeautifulSoup 找到物品卡片容器（div）。
提取每个卡片的 price、seller、reviews 和 url。
重要：工程师需先手动验证页面结构：
打开浏览器，访问 https://www.eldorado.gg/search?q=brainrot+rainbow。
按 F12 打开开发者工具，检查元素。
常见结构：
卡片容器：div[class*="offer-card"] 或 div[class*="product-item"]。
价格：span[class*="price"] 或 div[class*="amount"]（文本如 "$600"）。
卖家：a[class*="seller-name"] 或 span[class*="username"]。
评价：span[class*="rating"] 或 div[class*="reviews"]（文本如 "4.8 (15)"）。

如果不确定，用 page source 查看，并更新代码中的 selector。


处理输出：过滤无效项，按价格排序，取前 5-10 条。
防 ban 措施：
随机 User-Agent。
每请求延时 5-15 秒。
重试 3 次（如果 404 或 500）。
缓存结果，避免重复爬取。

错误处理：如果请求失败或无结果，返回空列表 + 日志。

4. 核心代码模板
用一个函数实现，易集成到后端 API（如 FastAPI）。
Pythonimport requests
from bs4 import BeautifulSoup
from fake_useragent import UserAgent
from tenacity import retry, stop_after_attempt, wait_exponential
from cachetools import TTLCache
import time
import random
import re

ua = UserAgent()
cache = TTLCache(maxsize=200, ttl=1800)  # 缓存 30 分钟，最大 200 项

@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=5, max=15))
def fetch_page(url, params=None):
    headers = {
        "User-Agent": ua.random,
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        "Accept-Language": "en-US,en;q=0.5",
        "Referer": "https://www.eldorado.gg/",
    }
    response = requests.get(url, headers=headers, params=params, timeout=15)
    response.raise_for_status()
    return response.text

def get_brainrot_prices(brainrot_name: str, mutation: str = "", traits: int = 0, max_results: int = 10) -> list[dict]:
    query = f"{brainrot_name} {mutation} {traits} traits".strip().replace(" ", "+")
    cache_key = query

    if cache_key in cache:
        return cache[cache_key]

    url = "https://www.eldorado.gg/search"
    params = {
        "q": query,
        "sort": "price_asc",  # 最低价优先
        # 可加其他过滤，如 game="roblox"
    }

    try:
        html = fetch_page(url, params)
        soup = BeautifulSoup(html, "html.parser")

        listings = []
        # 替换为实际 selector（工程师需验证）
        cards = soup.select('div.offer-card, div.product-item, div.item-container')  # 示例 selector

        for card in cards[:max_results]:
            # 价格提取
            price_elem = card.select_one('span.price, div.amount, [class*="price-value"]')
            price_text = price_elem.get_text(strip=True) if price_elem else ""
            price_match = re.search(r'\$?([\d,]+\.?\d*)', price_text)
            price = float(price_match.group(1).replace(",", "")) if price_match else None

            # 卖家名
            seller_elem = card.select_one('a.seller-name, span.username, [class*="seller-link"]')
            seller = seller_elem.get_text(strip=True) if seller_elem else "Unknown"

            # 评价
            reviews_elem = card.select_one('span.rating, div.reviews, [class*="rating-text"]')
            reviews = reviews_elem.get_text(strip=True) if reviews_elem else ""

            # URL
            link_elem = card.select_one('a[href]')
            item_url = "https://www.eldorado.gg" + link_elem['href'] if link_elem else ""

            if price is not None:
                listings.append({
                    "price": price,
                    "seller": seller,
                    "reviews": reviews,
                    "url": item_url
                })

        # 排序并缓存
        listings = sorted(listings, key=lambda x: x["price"])
        cache[cache_key] = listings
        return listings

    except Exception as e:
        print(f"错误: {e}")
        return []

    finally:
        time.sleep(random.uniform(5, 15))  # 延时

# 测试示例
if __name__ == "__main__":
    results = get_brainrot_prices("Lava Skibidi Toilet", "Rainbow", 5)
    print(results)
5. 测试计划

单元测试：用 pytest 测试函数（mock requests 返回固定 HTML）。
手动测试：输入不同查询，检查输出是否准确（价格正序，无重复）。
边缘案例：无结果查询（返回 []）；无效查询（404 处理）；大查询（限 max_results）。
性能测试：10 次连续调用，检查延时和缓存效果。

6. 部署与集成

后端集成：用 FastAPI 包装成 API 端点。Pythonfrom fastapi import FastAPI

app = FastAPI()

@app.get("/api/prices")
def prices(brainrot_name: str, mutation: str = "", traits: int = 0):
    return {"listings": get_brainrot_prices(brainrot_name, mutation, traits)}
运行：用 uvicorn app:app --reload。
服务器：部署到 AWS/Heroku，添加 cron 监控（每天检查 selector 是否变）。
日志：用 logging 记录每个请求和错误。

7. 注意事项与维护

页面变化：Eldorado 结构可能更新，每月手动检查一次 selector 并更新代码。
风险：如果被 ban，添加代理（如 smartproxy，配置 proxies={"http": "ip:port"}）。
升级：如果 JS 加载问题，用 playwright 替换 requests（见阶段2）。
合规：只抓公开数据，不登录/操作；遵守 TOS，避免高频。
扩展：未来加分页（如果结果 >1 页，循环 page=1,2...）。

工程师可以直接用这个模板开发。如果测试中发现 selector 不准，重新检查页面并调整。完成后，给我反馈结果，我们再优化。
